{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Classifiers to identify user from emails notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## email_preprocess.py\n",
    "This file reads email data from word_data.pkl and labeled data of its associated authors from email_authors.pkl. For simplicity 1 is labeled as Chris and 2 as Sara. The preprocess function reads the data and split the data into training set and testing set. Then vectorize the features set from string to list of number using TDIDF to simplify our feature set and then using feature selection select percentile method, top 10 percentile feature are set as training and testing set data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "import cPickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(words_file = \"../tools/word_data.pkl\", authors_file=\"../tools/email_authors.pkl\"):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "    \"\"\"\n",
    "\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, \"r\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, \"r\")\n",
    "    word_data = cPickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "\n",
    "    ### test_size is the percentage of events assigned to the test set\n",
    "    ### (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "\n",
    "\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "    ### info on the data\n",
    "    print \"no. of Chris training emails:\", sum(labels_train)\n",
    "    print \"no. of Sara training emails:\", len(labels_train)-sum(labels_train)\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier_author_id.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no. of Chris training emails:', 7936)\n",
      "('no. of Sara training emails:', 7884)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 1 (Naive Bayes) mini-project. \n",
    "    Use a Naive Bayes Classifier to identify emails by their authors\n",
    "    authors and labels:\n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.096 s\n",
      "Prediction time: 0.009 s\n",
      "Accuracy Score 0.920364050057\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf=GaussianNB()\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "t1=time()\n",
    "print \"Training time:\", round(time()-t0, 3), \"s\"\n",
    "pred=clf.predict(features_test)\n",
    "print \"Prediction time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Accuracy Score\",accuracy_score(labels_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 24.661 s\n",
      "Prediction time: 2.274 s\n",
      "Accuracy Score 0.959613196815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel=\"linear\")\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"Training time:\", round(time()-t0, 3), \"s\"\n",
    "t1=time()\n",
    "pred=clf.predict(features_test)\n",
    "print \"Prediction time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Accuracy Score\",accuracy_score(labels_test,pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC kernal='rbf' and C=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 13.347 s\n",
      "Prediction time: 1.015 s\n",
      "Accuracy Score 0.976109215017\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\",C=10000)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"Training time:\", round(time()-t0, 3), \"s\"\n",
    "t1=time()\n",
    "pred=clf.predict(features_test)\n",
    "print \"Prediction time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Accuracy Score\",accuracy_score(labels_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 66.004 s\n",
      "Prediction time: 6.286 s\n",
      "Accuracy Score 0.924914675768\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"rbf\",C=10)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"Training time:\", round(time()-t0, 3), \"s\"\n",
    "t1=time()\n",
    "pred=clf.predict(features_test)\n",
    "print \"Prediction time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Accuracy Score\",accuracy_score(labels_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision_Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.561 s\n",
      "Prediction time: 0.002 s\n",
      "Accuracy Score 0.967007963595\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"Training time:\", round(time()-t0, 3), \"s\"\n",
    "t1=time()\n",
    "pred=clf.predict(features_test)\n",
    "print \"Prediction time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Accuracy Score\",accuracy_score(labels_test,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
